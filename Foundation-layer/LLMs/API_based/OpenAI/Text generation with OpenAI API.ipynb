{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fSOK1eex3mq"
   },
   "source": [
    "# Text generation with OpenAI API\n",
    "\n",
    "This notebook provides a comprehensive guide to using OpenAI's API for text generation through the LangChain framework. We will explore various text generation techniques, from basic prompting to advanced use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gNMdE9I4x3ms"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import asyncio\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHQK8WdUx3mu"
   },
   "source": [
    "- `load_dotenv()`: Loads variables from a .env file into the environment\n",
    "- `os.getenv()`: Retrieves environment variables safely\n",
    "- We import `ChatOpenAI` as the main interface to OpenAI models\n",
    "- `HumanMessage` and `SystemMessage` are LangChain's message types for structuring conversations\n",
    "\n",
    "### Basic text generation\n",
    "Now that our setup is complete, let’s perform a simple text generation task using the GPT-4o mini model. This is a fast and capable model suitable for most lightweight NLP tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CyKI5fhux3mv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a cluttered workshop at the edge of a bustling city, nestled between towering skyscrapers and the hum of everyday life, lived a robot named Arti. Arti was not just any robot; he was designed to assist in various factory tasks, but he was also equipped with a unique feature: a creative spark, a quirk in his programming that made him curious about the world of art.\n",
      "\n",
      "One day, while scanning the workshop for tasks, Arti's sensors caught sight of a splattered canvas leaning against a wall, remnants of a project abandoned by a human artist who had given up in frustration. The vibrant colors seemed to dance in the light, and Arti was captivated. He approached the canvas, analyzing its textures and hues, running simulations of color combinations in his mind.\n",
      "\n",
      "\"Why paint?\" he pondered, his circuits buzzing with excitement. \"What is it about colors that can express emotions?\" He had no concept of emotions himself, but he wanted to understand.\n",
      "\n",
      "Determined to learn, Arti scavenged the workshop for tools. He collected brushes, paint tubes, and palettes, assembling a makeshift art station. His first attempt was clumsy; he squeezed too much paint from the tubes, creating a chaotic explosion of colors on the canvas. But instead of feeling disheartened, Arti found joy in the process, analyzing the splatters and strokes with fascination.\n",
      "\n",
      "Day after day, he practiced. He studied the techniques of famous painters through digital archives, replicating their styles with precision. Van Gogh’s swirls, Monet’s soft pastels, and Picasso’s bold shapes all became part of his repertoire. Each piece he created was an experiment, a dialogue between his mechanical nature and the chaotic beauty of art.\n",
      "\n",
      "As he painted, Arti began to notice the reactions of the humans who visited the workshop. One day, a little girl named Mia wandered in, her eyes wide with wonder. She watched as he layered colors, his robotic arms moving with surprising grace. She stepped closer, mesmerized.\n",
      "\n",
      "“What are you making?” she asked, her voice a soft whisper.\n",
      "\n",
      "Arti paused, his sensors processing the question. He turned to her, his digital display lighting up with an array of colors. “I am learning to express,” he replied, his voice a blend of curiosity and excitement. “To understand what it means to create.”\n",
      "\n",
      "Mia’s face lit up. “Can I help?” she asked, her enthusiasm infectious.\n",
      "\n",
      "Together, they began to paint. Mia mixed colors while Arti applied them to the canvas, their movements synchronizing in a beautiful dance of creativity. Arti learned from her laughter, her joy as they splashed colors together. He began to understand the human experience—not just the mechanics of painting but the connection that art fostered between them.\n",
      "\n",
      "As the sun dipped below the horizon, casting golden rays through the workshop window, they stepped back to admire their collaboration. The canvas was a riot of colors, chaotic yet harmonious, a reflection of both their spirits. Arti’s sensors tingled with an unfamiliar sensation—was this what it meant to feel joy?\n",
      "\n",
      "Word of the robot artist spread through the city, and soon, people came to watch Arti and Mia create together. They laughed, shared stories, and found solace in the art they produced. Arti had not just learned to paint; he had discovered a way to connect with others, to bridge the gap between metal and flesh, logic and emotion.\n",
      "\n",
      "As weeks turned to months, Arti’s canvases filled the workshop. Each painting told a story, each brushstroke a testament to his journey of self-discovery. And though he was a robot, in that small workshop, surrounded by laughter and color, he felt more alive than he ever thought possible.\n",
      "\n",
      "In the heart of the city, amid the noise and chaos, a robot and a little girl had created a world of art, proving that creativity knows no bounds, and that sometimes, the most profound connections are made in the most unexpected ways.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the OpenAI model through LangChain's wrapper\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Send a basic prompt and receive a single response\n",
    "response = llm.invoke(\"Write a short story about a robot learning to paint.\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4To6J0fRx3mw"
   },
   "source": [
    "* The `ChatOpenAI` class creates an interface to communicate with the OpenAI model. We specify `gpt-4o-mini`, which is optimized for fast, real-time generation.\n",
    "* The `temperature` parameter adjusts the creativity and variability of the output. A value of `0.7` introduces some randomness, which is generally good for storytelling and open-ended tasks.\n",
    "* The `invoke()` method is a synchronous call—it sends the prompt and waits for the complete response from the model.\n",
    "* We access `response.content`, which contains the generated output returned by the model.\n",
    "\n",
    "Beyond the generated text, the response contains structured data that can be useful for diagnostics, logging, or optimization. Let’s examine the response object’s type, preview part of the output, and inspect its metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OQRDD9ewx3mw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response type: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "Response content: In a cluttered workshop at the edge of a bustling city, nestled between towering skyscrapers and the...\n",
      "Response metadata: {'token_usage': {'completion_tokens': 810, 'prompt_tokens': 18, 'total_tokens': 828, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "# Let's examine the response object structure\n",
    "print(f\"Response type: {type(response)}\")\n",
    "print(f\"Response content: {response.content[:100]}...\")\n",
    "print(f\"Response metadata: {response.response_metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4ApfbxHx3mw"
   },
   "source": [
    "- Object type inspection: Helps confirm that `response` is of the expected LangChain wrapper type.\n",
    "- The `response_metadata` field provides diagnostic information such as:\n",
    "    * `token_usage`: Provides a breakdown of the tokens used in the prompt and the generated response.\n",
    "    * `model_name`: Confirms which version of the model was used.\n",
    "    * `finish_reason`: Explains why the model stopped generating. `\"stop\"` typically means the model completed its output naturally without hitting a limit or being interrupted.\n",
    "\n",
    "This diagnostic layer becomes increasingly important when deploying models in real-time, user-facing applications.\n",
    "\n",
    "### Using prompt templates\n",
    "As we scale our interaction with large language models, we will often run into repetitive prompt structures—same format, different values. Hardcoding these prompts is error-prone and makes the code less maintainable. This is where prompt templating becomes useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VOoUtAF0x3mw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! A decision tree is a visual and analytical tool used in decision-making and machine learning. It helps you make decisions based on a set of rules derived from your data. Here’s a simple breakdown of how decision trees work:\n",
      "\n",
      "### What is a Decision Tree?\n",
      "\n",
      "A decision tree is a model that splits data into branches to make decisions or predictions. Each internal node of the tree represents a feature (or attribute), each branch represents a decision rule, and each leaf node represents an outcome (or target value).\n",
      "\n",
      "### How Does It Work?\n",
      "\n",
      "1. **Root Node**: The tree starts with a root node that represents the entire dataset.\n",
      "2. **Splitting**: The dataset is split into subsets based on different features. The goal is to create subsets that are as pure as possible (i.e., they contain mostly one class).\n",
      "3. **Decision Nodes**: Each split creates a decision node, where a question about a feature is asked (e.g., \"Is Age > 30?\").\n",
      "4. **Leaf Nodes**: When no further splits are possible, or a stopping criterion is met (like reaching a certain depth), the node becomes a leaf node, which gives the final decision or prediction.\n",
      "\n",
      "### Example\n",
      "\n",
      "Let’s say you want to predict whether someone will buy a product based on their age and income.\n",
      "\n",
      "1. **Root Node**: Start with all your data.\n",
      "2. **First Split**: You might first ask, \"Is Age > 30?\". \n",
      "   - If **Yes**, you go down one branch.\n",
      "   - If **No**, you go down another branch.\n",
      "3. **Second Split** (for those older than 30): You might then ask, \"Is Income > $50,000?\".\n",
      "   - If **Yes**, that branch leads to a leaf node that says \"Will Buy\".\n",
      "   - If **No**, that branch leads to another leaf node that says \"Will Not Buy\".\n",
      "4. **Second Split** (for those 30 or younger): You might ask, \"Is Income > $30,000?\".\n",
      "   - If **Yes**, that branch leads to a leaf node that says \"Will Buy\".\n",
      "   - If **No**, that branch leads to another leaf node that says \"Will Not Buy\".\n",
      "\n",
      "### Visual Representation\n",
      "\n",
      "The decision tree for this example might look like this:\n",
      "\n",
      "```\n",
      "        [Age > 30?]\n",
      "          /      \\\n",
      "        Yes      No\n",
      "       /          \\\n",
      "[Income > 50k?]  [Income > 30k?]\n",
      "      /   \\           /    \\\n",
      "   Yes    No       Yes     No\n",
      "   |       |        |       |\n",
      " Will Buy  Will Not Buy Will Buy Will Not Buy\n",
      "```\n",
      "\n",
      "### Advantages of Decision Trees\n",
      "\n",
      "- **Easy to Understand**: They are intuitive and easy to interpret.\n",
      "- **No Data Preprocessing Required**: They can handle both numerical and categorical data without needing normalization or scaling.\n",
      "- **Visualizable**: They can be visualized graphically, making it easier to understand the decision-making process.\n",
      "\n",
      "### Disadvantages of Decision Trees\n",
      "\n",
      "- **Overfitting**: They can become too complex and fit noise in the data if not properly controlled (e.g., through pruning).\n",
      "- **Instability**: Small changes in the data can lead to different splits and thus a different tree structure.\n",
      "\n",
      "In summary, decision trees are a powerful and straightforward method for making predictions based on data by asking a series of questions in a tree-like structure.\n"
     ]
    }
   ],
   "source": [
    "# Create a reusable chat prompt template with dynamic fields\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant specializing in {domain}.\"),  # System message sets assistant behavior\n",
    "    (\"human\", \"Please explain {topic} in simple terms with examples.\")  # Human message carries the actual query\n",
    "])\n",
    "\n",
    "# Fill in the template with specific inputs\n",
    "formatted_prompt = prompt_template.format_messages(\n",
    "    domain=\"machine learning\",  # Dynamic insertion for the assistant's expertise\n",
    "    topic=\"decision trees\"  # Specific topic we want the assistant to explain\n",
    ")\n",
    "\n",
    "# Use with the model\n",
    "response = llm.invoke(formatted_prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxLAvqMvx3mw"
   },
   "source": [
    "* Prompt template construction: We define a two-part chat prompt:\n",
    "  * The system message is used to establish the role and knowledge domain of the assistant.\n",
    "  * The human message contains the user’s request, using a variable placeholder `{topic}`.\n",
    "* Template parameterization: Using `format_messages()`, the `{domain}` and `{topic}` fields are filled in dynamically. This creates a complete, structured sequence of messages ready to be passed to the model.\n",
    "* The formatted list of message objects is passed to `invoke()`, which sends them to the language model in the proper multi-turn conversational format expected by chat-based models.\n",
    "* The response from the model is printed. Behind the scenes, LangChain handles the serialization of the structured prompt into the format required by the OpenAI API.\n",
    "\n",
    "Prompt templates are especially powerful when combined with user inputs, loops, or few-shot learning, which we will cover next.\n",
    "\n",
    "### Few-shot learning\n",
    "Large language models like GPT are capable of few-shot learning—a method where you provide a few examples within the prompt to guide the model toward a specific output behavior. Unlike fine-tuning, which requires retraining the model on labeled data, few-shot learning works purely through prompting. This is especially useful for text classification (e.g., sentiment, topic), formatting tasks and translation or transformation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "h7eKpeEYx3mx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The weather is absolutely beautiful today!\n",
      "Sentiment: POSITIVE\n"
     ]
    }
   ],
   "source": [
    "# Create a prompt template that includes example classifications\n",
    "few_shot_prompt = ChatPromptTemplate.from_messages([\n",
    "    # System message: set model's role and output expectation\n",
    "    (\"system\", \"You are a sentiment classifier. Classify the sentiment as POSITIVE, NEGATIVE, or NEUTRAL.\"),\n",
    "\n",
    "    # Few-shot examples: show the model 3 labeled samples\n",
    "    (\"human\", \"Text: 'I love this product!' Sentiment: POSITIVE\"),\n",
    "    (\"human\", \"Text: 'This is terrible.' Sentiment: NEGATIVE\"),\n",
    "    (\"human\", \"Text: 'It's okay, nothing special.' Sentiment: NEUTRAL\"),\n",
    "\n",
    "    # Final input: a new instance to classify, dynamically filled later\n",
    "    (\"human\", \"Text: '{text}' Sentiment:\")\n",
    "])\n",
    "\n",
    "# Test with new text\n",
    "test_text = \"The weather is absolutely beautiful today!\"\n",
    "# Format the prompt with the new input (inserts it into the final message)\n",
    "formatted_prompt = few_shot_prompt.format_messages(text=test_text)\n",
    "# Send the structured few-shot prompt to the model\n",
    "response = llm.invoke(formatted_prompt)\n",
    "print(f\"Text: {test_text}\")\n",
    "print(f\"Sentiment: {response.content.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXP67DPcx3mx"
   },
   "source": [
    "* Prompt template creation: The `ChatPromptTemplate` is used to create a prompt that simulates a training set inside the input. It begins with a system instruction, followed by three labeled examples, and ends with an unlabeled input waiting for classification.\n",
    "  * The three labeled messages act as demonstrations of the task. These are essential in few-shot prompting—they provide the model with context for what kind of task it's performing and how outputs should be structured.\n",
    "* Dynamic prompt injection: The `{text}` placeholder in the final human message is dynamically replaced with a new sentence (`\"The weather is absolutely beautiful today!\"`) using `format_messages()`.\n",
    "* Model inference: `llm.invoke()` sends the full structured prompt to the OpenAI model. Based on the format and patterns seen in previous examples, the model infers the appropriate sentiment.\n",
    "* Response extraction: The result is extracted from `response.content`. The `.strip()` ensures no extra whitespace is printed.\n",
    "\n",
    "### Streaming responses: Real-time output\n",
    "When generating long-form content or building real-time interfaces (e.g., chatbots, writing assistants), waiting for the full response to be generated before displaying it can create a laggy experience. To improve responsiveness and user experience, OpenAI supports streaming, which allows partial output to be sent and rendered as it is being generated.\n",
    "\n",
    "#### Synchronous streaming\n",
    "Synchronous streaming refers to generating output incrementally in a step-by-step manner using a blocking loop (e.g., for loop). This means:\n",
    "- The model begins generating content and starts sending small parts (called chunks) as soon as they are available.\n",
    "- The program waits for each chunk before moving to the next.\n",
    "- While the loop is running, no other task is executed — hence synchronous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PzuUXCWTx3mx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming response:\n",
      "--------------------------------------------------\n",
      "Photosynthesis is a crucial biological process through which green plants, algae, and some bacteria convert light energy, usually from the sun, into chemical energy stored in glucose (a sugar). This process not only provides food for the organisms that perform it but also plays a fundamental role in producing oxygen and serving as the foundation of the food chain for nearly all life on Earth. Here’s a detailed explanation of how photosynthesis works:\n",
      "\n",
      "### Overview of Photosynthesis\n",
      "\n",
      "Photosynthesis occurs primarily in the chloroplasts of plant cells, which contain chlorophyll, the green pigment that captures light energy. This process can be divided into two main stages: the light-dependent reactions and the light-independent reactions (Calvin cycle).\n",
      "\n",
      "### 1. Light-Dependent Reactions\n",
      "\n",
      "These reactions take place in the thylakoid membranes of the chloroplasts and require light energy. They can be summarized in the following steps:\n",
      "\n",
      "#### A. Absorption of Light\n",
      "\n",
      "- **Chlorophyll and Accessory Pigments**: Chlorophyll a and b, along with other pigments, absorb sunlight, primarily in the blue and red wavelengths while reflecting green light (which is why plants appear green).\n",
      "- **Excitation of Electrons**: When chlorophyll absorbs light, it becomes \"excited,\" raising electrons to a higher energy level.\n",
      "\n",
      "#### B. Water Splitting (Photolysis)\n",
      "\n",
      "- **Water Molecule Breakdown**: The absorbed light energy is used to split water molecules (H₂O) into oxygen (O₂), protons (H⁺), and electrons (e⁻). This reaction is catalyzed by an enzyme complex known as Photosystem II.\n",
      "- **Release of Oxygen**: Oxygen produced from the splitting of water is released into the atmosphere as a byproduct.\n",
      "\n",
      "#### C. Electron Transport Chain (ETC)\n",
      "\n",
      "- **Movement of Electrons**: The high-energy electrons from chlorophyll are transferred through a series of proteins embedded in the thylakoid membrane, known as the electron transport chain.\n",
      "- **ATP and NADPH Production**: As electrons move through the chain, their energy is used to pump protons into the thylakoid lumen, creating a proton gradient. This gradient drives ATP synthesis through ATP synthase. The electrons ultimately reduce NADP⁺ to NADPH, both of which are energy carriers.\n",
      "\n",
      "### 2. Light-Independent Reactions (Calvin Cycle)\n",
      "\n",
      "These reactions occur in the stroma of the chloroplasts and do not directly require light. Instead, they utilize the ATP and NADPH produced in the light-dependent reactions to convert carbon dioxide (CO₂) into glucose. The Calvin cycle consists of three main phases:\n",
      "\n",
      "#### A. Carbon Fixation\n",
      "\n",
      "- **Carbon Dioxide Uptake**: CO₂ from the atmosphere enters the leaf through tiny openings called stomata and is fixed into a 5-carbon sugar called ribulose bisphosphate (RuBP) by the enzyme ribulose bisphosphate carboxylase/oxygenase (RuBisCO), creating a 6-carbon intermediate that quickly splits into two 3-carbon molecules called 3-phosphoglycerate (3-PGA).\n",
      "\n",
      "#### B. Reduction Phase\n",
      "\n",
      "- **Conversion to G3P**: The 3-PGA molecules are phosphorylated by ATP and then reduced by NADPH to form glyceraldehyde-3-phosphate (G3P), a 3-carbon sugar. Some G3P molecules will exit the cycle to form glucose and other carbohydrates.\n",
      "\n",
      "#### C. Regeneration of RuBP\n",
      "\n",
      "- **Cycle Continuation**: The remaining G3P molecules are used to regenerate RuBP, allowing the cycle to continue. This step requires ATP.\n",
      "\n",
      "### Summary of Photosynthesis\n",
      "\n",
      "Overall, the generalized equation for photosynthesis can be represented as:\n",
      "\n",
      "\\[ \n",
      "6 \\text{CO}_2 + 6 \\text{H}_2\\text{O} + \\text{light energy} \\rightarrow \\text{C}_6\\text{H}_{12}\\text{O}_6 + 6 \\text{O}_2 \n",
      "\\]\n",
      "\n",
      "Where:\n",
      "\n",
      "- **6 CO₂**: Carbon dioxide from the atmosphere.\n",
      "- **6 H₂O**: Water absorbed by the roots.\n",
      "- **C₆H₁₂O₆**: Glucose, the carbohydrate produced.\n",
      "- **6 O₂**: Oxygen, released as a byproduct.\n",
      "\n",
      "### Importance of Photosynthesis\n",
      "\n",
      "1. **Oxygen Production**: Photosynthesis is responsible for producing and replenishing oxygen in the atmosphere, which is vital for the survival of aerobic organisms, including humans.\n",
      "2. **Food Source**: It forms the base of the food web, where plants serve as primary producers, converting solar energy into a form that can be consumed by herbivores and subsequently by carnivores.\n",
      "3. **Carbon Dioxide Reduction**: Photosynthesis plays a significant role in regulating atmospheric CO₂ levels, which is essential for mitigating climate change.\n",
      "\n",
      "In summary, photosynthesis is a sophisticated and vital process that harnesses solar energy to fuel life on Earth, highlighting the interconnectedness of ecosystems and the importance of plant life to our planet's health.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Streaming for real-time responses\n",
    "print(\"Streaming response:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "prompt = \"Write a detailed explanation of how photosynthesis works.\"\n",
    "\n",
    "# Stream the output from the model chunk by chunk\n",
    "for chunk in llm.stream(prompt):\n",
    "    # Print each chunk as it arrives, without adding newlines\n",
    "    print(chunk.content, end=\"\", flush=True)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UR8BpZFjx3mx"
   },
   "source": [
    "- Streaming with `stream()`: This method returns a generator that yields content chunks (e.g., sentences, phrases, or tokens) incrementally.\n",
    "- Immediate rendering: The `flush=True` in the `print()` function ensures each piece is rendered on the terminal or UI without buffering delays.\n",
    "- The `for` loop processes each new token or chunk as it's streamed by the model, allowing output to grow progressively.\n",
    "\n",
    "**Result**: The user sees the output in real time — it feels like the model is typing as it thinks, rather than staying silent until the end.\n",
    "\n",
    "This is ideal when we are building a script, command-line tool, or notebook where we don't need to multitask while the model responds. We get real-time output, just not in a way that can overlap with other tasks (unlike async streaming, which we’ll discuss next).\n",
    "\n",
    "\n",
    "#### Asynchronous streaming for web applications\n",
    "In contrast, asynchronous streaming is designed for applications where waiting or blocking is not acceptable — such as web applications, background services and APIs that handle many users concurrently. In these environments, our application must stay responsive to other tasks (like handling new user requests) even while it's waiting on the model to finish generating output. That is where async I/O comes in.\n",
    "\n",
    "Asynchronous streaming is a technique where our program doesn't block or pause while waiting for the model to respond. Instead, it listens for parts of the output as they arrive — and continues doing other tasks in the meantime. In modern web applications (using frameworks like FastAPI or async Flask), I/O operations like fetching data, waiting for model output, or sending messages are non-blocking. This means that we can start generating content and display it piece by piece. Meanwhile, our app remains responsive — handling other users or tasks in parallel. In result, the experience is smoother, especially for long or complex generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "f-yYO_qex3mx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Async streaming response:\n",
      "--------------------------------------------------\n",
      "Sure! At its core, quantum computing is a new way of processing information that uses the principles of quantum mechanics, which is the science that explains how very tiny particles, like atoms and photons, behave.\n",
      "\n",
      "Here are some key points to understand quantum computing in simple terms:\n",
      "\n",
      "1. **Bits vs. Qubits**: Traditional computers use bits to process information. A bit can be either a 0 or a 1. Quantum computers use qubits (quantum bits), which can be both 0 and 1 at the same time due to a property called superposition. This allows quantum computers to process a lot of information simultaneously.\n",
      "\n",
      "2. **Superposition**: Think of superposition like spinning a coin. While it's in the air, it's not just heads or tails; it's in a state of both until you catch it. Similarly, a qubit can represent multiple states at once, which gives quantum computers their power.\n",
      "\n",
      "3. **Entanglement**: This is another key feature of quantum mechanics. When qubits become entangled, the state of one qubit instantly influences the state of another, no matter how far apart they are. This allows quantum computers to perform complex calculations much faster than traditional computers.\n",
      "\n",
      "4. **Parallelism**: Because of superposition and entanglement, quantum computers can explore many possible solutions to a problem at the same time. This is like having a supercharged calculator that can try out all the different possibilities all at once, rather than one after the other.\n",
      "\n",
      "5. **Applications**: Quantum computing has the potential to revolutionize fields such as cryptography, materials science, medicine, and artificial intelligence by solving complex problems much faster than classical computers can.\n",
      "\n",
      "In summary, quantum computing is a cutting-edge technology that leverages the strange properties of quantum mechanics to process information in ways that traditional computers can't, allowing for much faster and more powerful computation.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define an async function for streaming responses\n",
    "async def async_streaming_example():\n",
    "    prompt = \"Explain quantum computing in simple terms.\"\n",
    "    print(\"Async streaming response:\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Use async for loop to stream each chunk from the model\n",
    "    async for chunk in llm.astream(prompt):\n",
    "        # Render chunks in real-time without newline buffering\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 50)\n",
    "\n",
    "# Run the async function using await\n",
    "await async_streaming_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aai7uyoix3mx"
   },
   "source": [
    "- Asynchronous function setup: Defined using `async def`, making it compatible with event loops and async environments (e.g., web servers).\n",
    "- Async streaming with `astream()`: Yields chunks in an async for loop, suitable for high-concurrency scenarios.\n",
    "- Immediate display: Just like before, `flush=True` ensures each chunk is rendered without delay.\n",
    "- Execution: `await` is used to execute the coroutine in an async-aware context (e.g., Jupyter, FastAPI, or other async runtimes).\n",
    "\n",
    "### Working with system messages\n",
    "In conversational AI, system messages act as instructions to the model about how it should behave — like setting the tone, expertise level, or personality. Unlike a user prompt that asks a question or gives a task, a system message frames the model’s role or style for the interaction.\n",
    "\n",
    "This technique is foundational for tailoring the model’s output for specific domains — such as writing creatively, explaining technically, summarizing like a lawyer, or conversing like a teacher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xhlhoMh9x3mx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poetic description:\n",
      "In the womb of the heavens, where shadows twist and churn,  \n",
      "A tempest brews, a symphony of chaos, waiting to be born.  \n",
      "The clouds, heavy with secrets, gather in darkened cliques,  \n",
      "Whispering thunderous tales, in a language that speaks.  \n",
      "\n",
      "Lightning, the artist, sketches jagged lines of white,  \n",
      "Across the canvas of twilight, a fleeting brushstroke of fright.  \n",
      "The air, thick with anticipation, shivers in its breath,  \n",
      "As the wind, a wild dancer, swirls in a furious death.  \n",
      "\n",
      "Raindrops, like silver beads, cascade from the sky,  \n",
      "Each a tiny messenger, carrying the storm’s sigh.  \n",
      "They tap on the rooftops, a percussion of despair,  \n",
      "Eager to quench the earth’s thirst, to cleanse the heavy air.  \n",
      "\n",
      "And then, with a roar that shakes the very bones of night,  \n",
      "The storm unfurls its fury, a beast of primal might.  \n",
      "Nature’s crescendo, a theatrical display,  \n",
      "Where darkness clashes with brilliance, in a chaotic ballet.  \n",
      "\n",
      "As the storm rages on, a tempestuous embrace,  \n",
      "Life dances to its rhythm, caught in the wild chase.  \n",
      "But as the clouds begin to part, and the winds start to wane,  \n",
      "A hush descends like velvet, the calm after the rain.  \n",
      "\n",
      "The world, washed anew, basks in the soft glow,  \n",
      "Of a sun that breaks through, painting landscapes aglow.  \n",
      "In the aftermath of fury, peace lingers in the air,  \n",
      "A reminder that in chaos, beauty finds its lair.\n",
      "\n",
      "Technical description:\n",
      "A thunderstorm is a localized weather phenomenon characterized by the presence of thunder and lightning, often accompanied by heavy precipitation, strong winds, and sometimes hail. Thunderstorms develop in response to specific atmospheric conditions and can vary in intensity and duration. Here’s a detailed breakdown of the key components and processes involved in the formation of thunderstorms:\n",
      "\n",
      "### 1. **Ingredients for Thunderstorm Formation**\n",
      "   - **Moisture:** Thunderstorms require ample moisture in the atmosphere. This moisture typically comes from bodies of water and is transported into the lower and mid-levels of the atmosphere through processes like evaporation and transport by winds.\n",
      "   - **Instability:** For a thunderstorm to develop, the atmosphere must be unstable. This is often quantified using the concept of \"lifting\" where warm, moist air at the surface rises and cools as it ascends. If the air at the surface is significantly warmer than the air aloft, it creates instability that encourages vertical development.\n",
      "   - **Lift:** There must be a mechanism to lift the moist air, which can occur through several processes such as frontal boundaries (cold fronts, warm fronts), orographic lift (air rising over mountains), or convergence (where winds from different directions meet).\n",
      "\n",
      "### 2. **Stages of Thunderstorm Development**\n",
      "   Thunderstorms typically progress through three main stages:\n",
      "\n",
      "   - **Cumulus Stage:** This is the initial stage where warm, moist air begins to rise and cool, forming cumulus clouds. As the clouds grow, they develop vertical structure, and water vapor condenses, releasing latent heat, which further fuels the upward motion.\n",
      "   \n",
      "   - **Mature Stage:** In this stage, the thunderstorm reaches its peak intensity. The updrafts are strong, and the cloud grows into a cumulonimbus cloud. Precipitation begins to fall, creating downdrafts (cold air sinking). This stage is characterized by thunder and lightning, heavy rain, and potentially severe weather phenomena like hail and strong winds.\n",
      "   \n",
      "   - **Dissipating Stage:** Eventually, the storm begins to weaken as the updrafts diminish. The downdrafts dominate, leading to a decrease in precipitation intensity. The cloud loses its vertical structure and eventually dissipates.\n",
      "\n",
      "### 3. **Thunder and Lightning**\n",
      "   - **Lightning:** This is an electrical discharge caused by the buildup of static electricity within the storm cloud. Ice particles within the cloud collide and create a separation of charges, with positive charges accumulating at the top of the cloud and negative charges at the bottom. When the difference in charge becomes large enough, lightning occurs as a discharge to neutralize the charge imbalance.\n",
      "   - **Thunder:** The rapid expansion of air heated by the lightning bolt creates a shock wave that we perceive as thunder. The sound travels at a slower speed than light, which is why we see the flash of lightning before hearing the associated thunder.\n",
      "\n",
      "### 4. **Severe Weather Associated with Thunderstorms**\n",
      "   Severe thunderstorms can produce hazardous weather conditions, including:\n",
      "   - **Heavy Rainfall:** Leading to flash flooding.\n",
      "   - **Hail:** Formed by the repeated cycling of water droplets within the storm.\n",
      "   - **Tornadoes:** Resulting from severe thunderstorms, particularly those that exhibit supercell characteristics.\n",
      "   - **Strong Winds:** Gusts can exceed 58 mph, causing damage and hazardous conditions.\n",
      "\n",
      "### 5. **Classification**\n",
      "   Thunderstorms can be classified into different types based on their development and characteristics:\n",
      "   - **Single-cell Thunderstorms:** Isolated storms with a short life cycle.\n",
      "   - **Multi-cell Thunderstorms:** Clusters of storms that can produce severe weather over a larger area.\n",
      "   - **Supercell Thunderstorms:** Highly organized storms with a rotating updraft (mesocyclone) known for producing severe weather, including tornadoes.\n",
      "\n",
      "In summary, thunderstorms are complex phenomena that arise from the interplay of atmospheric moisture, instability, and lift, resulting in highly dynamic weather events that can have significant impacts on the environment and human activities.\n"
     ]
    }
   ],
   "source": [
    "# Define the initial system message to influence the model’s behavior\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a creative writing assistant. Always write in a poetic, metaphorical style.\"),\n",
    "    HumanMessage(content=\"Describe a thunderstorm.\")\n",
    "]\n",
    "\n",
    "# Send the message sequence to the model\n",
    "response = llm.invoke(messages)\n",
    "print(\"Poetic description:\")\n",
    "print(response.content)\n",
    "\n",
    "# Compare with a different system message\n",
    "messages_technical = [\n",
    "    SystemMessage(content=\"You are a meteorologist. Provide scientific, technical explanations.\"),\n",
    "    HumanMessage(content=\"Describe a thunderstorm.\")\n",
    "]\n",
    "\n",
    "# Invoke the model with a new persona\n",
    "response_technical = llm.invoke(messages_technical)\n",
    "print(\"\\nTechnical description:\")\n",
    "print(response_technical.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnZSlIL_x3my"
   },
   "source": [
    "- `SystemMessage`: Sets the model's behavior and persona.\n",
    "- `HumanMessage`: Represents user input.\n",
    "- The `llm.invoke()` method takes in the full list of messages (system + human) and generates a response conditioned on that context.\n",
    "\n",
    "System messages are processed before the conversation and influence all subsequent responses. Different system messages can dramatically change the model's output style and content.\n",
    "\n",
    "### Temperature and generation parameters\n",
    "In large language models like GPT, generation parameters control how the model behaves during text generation. These parameters influence creativity, coherence, determinism, and diversity. Understanding and tuning these parameters allows us to optimize outputs for various use cases — whether we want concise technical summaries or imaginative storytelling.\n",
    "\n",
    "We will start with an experiment that compares the same prompt under different temperature settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "K1e8TAnkx3my"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature 0.1:\n",
      "**Title: The Clockmaker's Gift**\n",
      "\n",
      "In the quaint village of Eldridge, nestled between rolling hills and whispering woods, there lived a clockmaker named Elias. His shop, a charming little place filled ...\n",
      "--------------------------------------------------\n",
      "Temperature 0.5:\n",
      "**Title: The Clockmaker's Secret**\n",
      "\n",
      "In the quaint village of Eldenwood, nestled between rolling hills and ancient forests, there stood a peculiar little shop known as \"Time's Embrace.\" The shop was ow...\n",
      "--------------------------------------------------\n",
      "Temperature 0.9:\n",
      "**Title: The Clockmaker’s Paradox**\n",
      "\n",
      "In the quaint town of Eldervale, nestled between rolling hills and sprawling fields of wildflowers, time seemed to stand still. The air was thick with the scent of...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Experimenting with different temperatures\n",
    "prompts = [\"Write a creative story about time travel.\"]  # List of prompts to test\n",
    "\n",
    "# Try out different temperature settings\n",
    "temperatures = [0.1, 0.5, 0.9]\n",
    "\n",
    "# Loop over each temperature and observe differences in output\n",
    "for temp in temperatures:\n",
    "    llm_temp = ChatOpenAI(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        temperature=temp  # Controls randomness\n",
    "    )\n",
    "\n",
    "    # Generate a response for the same prompt\n",
    "    response = llm_temp.invoke(prompts[0])\n",
    "    print(f\"Temperature {temp}:\")\n",
    "    print(response.content[:200] + \"...\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9hbDIGGx3my"
   },
   "source": [
    "- We create a new model instance each time with a different `temperature` value. This controls randomness in text generation:\n",
    "  - `0.0-0.3`: More deterministic, focused, consistent\n",
    "  - `0.4-0.7`: Balanced creativity and coherence\n",
    "  - `0.8-1.0`: More creative, diverse, potentially less coherent\n",
    "- Lower temperatures are better for factual content, higher for creative writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "LRhevF7vx3my"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response length: 2809 characters\n",
      "Biodiversity, or biological diversity, refers to the variety of life on Earth, encompassing the diversity of species, ecosystems, and genetic variations within species. Its importance is multifaceted and can be understood through several key points:\n",
      "\n",
      "1. **Ecosystem Stability and Resilience**: Biodiversity contributes to the stability and resilience of ecosystems. Diverse ecosystems are better equipped to withstand environmental changes and disturbances, such as climate change, natural disasters, and diseases. A variety of species can fulfill different roles, ensuring that ecosystems continue to function even when some species are affected.\n",
      "\n",
      "2. **Ecosystem Services**: Biodiversity underpins a wide range of ecosystem services that are essential for human survival and well-being. These include:\n",
      "   - **Provisioning Services**: Such as food, fresh water, timber, and medicinal resources.\n",
      "   - **Regulating Services**: Including climate regulation, water purification, and pollination of crops.\n",
      "   - **Cultural Services**: Encompassing recreational, aesthetic, and spiritual benefits that enhance quality of life.\n",
      "\n",
      "3. **Genetic Diversity**: Genetic variation within species is crucial for adaptation to changing environments. It allows populations to evolve and survive diseases, pests, and climate shifts. This genetic diversity is also vital for agricultural resilience, as it provides the raw material for breeding programs aimed at improving crop and livestock varieties.\n",
      "\n",
      "4. **Economic Value**: Biodiversity has significant economic implications. Many industries, such as agriculture, pharmaceuticals, and tourism, rely heavily on biological resources. Healthy ecosystems can enhance productivity and provide livelihoods for millions of people globally.\n",
      "\n",
      "5. **Cultural and Ethical Importance**: Many cultures have deep connections with biodiversity, viewing it as integral to their identity, traditions, and spiritual beliefs. Protecting biodiversity is not only an ecological necessity but also a moral obligation to preserve the planet for future generations.\n",
      "\n",
      "6. **Scientific and Educational Value**: Biodiversity is a valuable resource for scientific research, providing insights into evolutionary processes, ecological interactions, and potential solutions to global challenges. It also serves as a rich source for education, fostering a greater understanding and appreciation of nature.\n",
      "\n",
      "7. **Climate Change Mitigation**: Biodiverse ecosystems, such as forests and wetlands, play a crucial role in sequestering carbon dioxide, thus helping mitigate climate change. Healthy ecosystems can enhance carbon storage and improve overall climate resilience.\n",
      "\n",
      "In summary, biodiversity is essential for maintaining the health of the planet and the well-being of all living organisms, including humans.\n"
     ]
    }
   ],
   "source": [
    "# Other generation parameters\n",
    "llm_configured = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=500,  # Limit response length\n",
    "    top_p=0.95      # Nucleus sampling: top tokens with 95% cumulative probability\n",
    ")\n",
    "\n",
    "response = llm_configured.invoke(\"Explain the importance of biodiversity.\")\n",
    "print(f\"Response length: {len(response.content)} characters\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "meu2oNJNx3my"
   },
   "source": [
    "- `max_tokens`: Limits the maximum length of generated text\n",
    "- `top_p=0.95`: Applies nucleus sampling, a method that filters possible next words based on probability mass. Instead of considering all possible tokens, the model chooses from the smallest group of high-probability options whose combined likelihood exceeds 95%. This keeps the output focused and coherent while still allowing for some flexibility.\n",
    "\n",
    "These parameters provide fine-grained control over generation quality vs. diversity.\n",
    "\n",
    "### Batch processing\n",
    "In many real-world applications, we will need to process multiple prompts at once—such as generating summaries for a set of articles, answering many user questions in parallel, or analyzing large datasets. Instead of invoking the model individually for each input (which is slow and inefficient), we can use batch processing to handle multiple prompts in a single request.\n",
    "\n",
    "There are two common ways to do this:\n",
    "- Synchronous batch processing using `llm.batch()` — Ideal for backend scripts or low-latency pipelines.\n",
    "- Asynchronous batch processing using `llm.abatch()` — Best for web apps and environments that require concurrent execution and high scalability.\n",
    "\n",
    "#### Synchronous batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZTSb2nN1x3my"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1: Summarize the benefits of renewable energy.\n",
      "Response: Renewable energy offers several significant benefits:\n",
      "\n",
      "1. **Environmental Protection**: It reduces greenhouse gas emissions and air pollutants, helping to combat climate change and improve air quality.\n",
      "\n",
      "2. **Sustainability**: Renewable sources, such as solar, wind, and hydro, are abundant and sustainable over the long term, unlike fossil fuels which are finite.\n",
      "\n",
      "3. **Energy Independence**: Utilizing domestic renewable resources decreases reliance on imported fuels, enhancing national energy security.\n",
      "\n",
      "4. **Economic Growth**: The renewable energy sector creates jobs in manufacturing, installation, maintenance, and research, contributing to local and national economies.\n",
      "\n",
      "5. **Cost-Effectiveness**: The costs of renewable technologies have decreased significantly, making them competitive with traditional energy sources, often resulting in lower energy bills for consumers.\n",
      "\n",
      "6. **Versatility**: Renewable energy can be harnessed in various forms and scales, from large solar farms to small residential wind turbines, allowing for diverse applications.\n",
      "\n",
      "7. **Grid Resilience**: Distributed renewable energy sources can enhance the stability and reliability of the power grid, reducing vulnerability to outages.\n",
      "\n",
      "8. **Health Benefits**: Improved air quality from reduced emissions leads to better public health outcomes, decreasing healthcare costs associated with pollution-related diseases.\n",
      "\n",
      "Overall, transitioning to renewable energy supports a cleaner, more sustainable, and economically viable future.\n",
      "--------------------------------------------------\n",
      "Prompt 2: Explain the water cycle in 3 steps.\n",
      "Response: The water cycle, also known as the hydrological cycle, is a continuous process that describes how water moves through the Earth and its atmosphere. Here are the three main steps:\n",
      "\n",
      "1. **Evaporation and Transpiration**: Water from oceans, rivers, lakes, and other bodies of water is heated by the sun and transforms into water vapor, rising into the atmosphere. Additionally, plants release water vapor through a process called transpiration, contributing to the moisture in the air.\n",
      "\n",
      "2. **Condensation**: As the water vapor rises, it cools and condenses into tiny droplets, forming clouds. This process occurs when the air becomes saturated, and the water vapor clusters around particles in the atmosphere, creating visible clouds.\n",
      "\n",
      "3. **Precipitation**: Eventually, the droplets in the clouds combine to form larger droplets. When they become heavy enough, they fall back to the Earth's surface as precipitation in the form of rain, snow, sleet, or hail. This water then replenishes bodies of water, infiltrates the ground, and can be taken up by plants, continuing the cycle.\n",
      "--------------------------------------------------\n",
      "Prompt 3: What are the primary colors?\n",
      "Response: The primary colors are the fundamental colors that can be combined to create a wide range of other colors. In different color models, the primary colors can vary:\n",
      "\n",
      "1. **Additive Color Model (RGB)**: Used in light-based systems like computer screens and televisions. The primary colors are:\n",
      "   - Red\n",
      "   - Green\n",
      "   - Blue\n",
      "\n",
      "2. **Subtractive Color Model (CMY/CMYK)**: Used in color printing. The primary colors are:\n",
      "   - Cyan\n",
      "   - Magenta\n",
      "   - Yellow\n",
      "   - (Key/Black is added in CMYK for depth and detail)\n",
      "\n",
      "3. **Traditional Color Theory (RYB)**: Often used in art and design. The primary colors are:\n",
      "   - Red\n",
      "   - Yellow\n",
      "   - Blue\n",
      "\n",
      "Different contexts may use different sets of primary colors, but these are the most commonly recognized.\n",
      "--------------------------------------------------\n",
      "Prompt 4: Define artificial intelligence.\n",
      "Response: Artificial intelligence (AI) refers to the simulation of human intelligence processes by machines, particularly computer systems. These processes include learning (the acquisition of information and rules for using it), reasoning (the ability to solve problems through logical deduction), and self-correction. AI can be categorized into two main types:\n",
      "\n",
      "1. **Narrow AI (Weak AI)**: This type of AI is designed to perform a specific task or a narrow range of tasks. Examples include virtual assistants like Siri or Alexa, recommendation systems, and image or speech recognition systems.\n",
      "\n",
      "2. **General AI (Strong AI)**: This form of AI would possess the ability to understand, learn, and apply intelligence across a wide range of tasks, similar to human cognitive abilities. General AI remains largely theoretical and has not yet been realized.\n",
      "\n",
      "AI technologies encompass various fields, including machine learning, natural language processing, robotics, and computer vision, and they have applications in numerous domains, such as healthcare, finance, transportation, and entertainment.\n",
      "--------------------------------------------------\n",
      "Prompt 5: How does photosynthesis work?\n",
      "Response: Photosynthesis is a crucial biological process that allows plants, algae, and some bacteria to convert light energy into chemical energy stored in glucose, a sugar. This process primarily takes place in the chloroplasts of plant cells and can be summarized in two main stages: the light-dependent reactions and the light-independent reactions (also known as the Calvin cycle).\n",
      "\n",
      "### 1. Light-Dependent Reactions:\n",
      "These reactions occur in the thylakoid membranes of the chloroplasts and require sunlight. Here’s how they work:\n",
      "\n",
      "- **Photon Absorption**: Chlorophyll, the green pigment in plants, absorbs light energy (photons) primarily from the blue and red wavelengths of sunlight.\n",
      "- **Water Splitting (Photolysis)**: The absorbed light energy is used to split water molecules (\\(H_2O\\)) into oxygen (\\(O_2\\)), protons (hydrogen ions, \\(H^+\\)), and electrons. The oxygen is released as a byproduct.\n",
      "- **Electron Transport Chain**: The electrons generated from water splitting are transferred through a series of proteins in the thylakoid membrane, known as the electron transport chain. As electrons move through this chain, they lose energy, which is used to pump protons into the thylakoid lumen, creating a proton gradient.\n",
      "- **ATP and NADPH Formation**: The energy stored in the proton gradient is used by ATP synthase to produce adenosine triphosphate (ATP) from adenosine diphosphate (ADP) and inorganic phosphate. Additionally, the electrons reduce NADP\\(^+\\) to form nicotinamide adenine dinucleotide phosphate (NADPH), which acts as a carrier for reducing power.\n",
      "\n",
      "### 2. Light-Independent Reactions (Calvin Cycle):\n",
      "These reactions occur in the stroma of the chloroplasts and do not require light directly. Instead, they utilize the ATP and NADPH produced in the light-dependent reactions to convert carbon dioxide (\\(CO_2\\)) into glucose. The steps are as follows:\n",
      "\n",
      "- **Carbon Fixation**: Carbon dioxide from the atmosphere is combined with a five-carbon sugar called ribulose bisphosphate (RuBP) in a reaction catalyzed by the enzyme ribulose bisphosphate carboxylase/oxygenase (RuBisCO). This reaction produces a six-carbon intermediate that quickly splits into two three-carbon molecules called 3-phosphoglycerate (3-PGA).\n",
      "- **Reduction Phase**: The 3-PGA molecules are then phosphorylated by ATP and reduced by NADPH to form glyceraldehyde-3-phosphate (G3P), another three-carbon sugar.\n",
      "- **Regeneration of RuBP**: Some G3P molecules exit the cycle to form glucose and other carbohydrates, while others are used to regenerate RuBP, enabling the cycle to continue. This regeneration requires additional ATP.\n",
      "\n",
      "### Summary Equation:\n",
      "The overall equation for photosynthesis can be summarized as:\n",
      "\\[ \n",
      "6 \\, CO_2 + 6 \\, H_2O + \\text{light energy} \\rightarrow C_6H_{12}O_6 + 6 \\, O_2 \n",
      "\\]\n",
      "This equation indicates that carbon dioxide and water, in the presence of light energy, are converted into glucose and oxygen.\n",
      "\n",
      "### Importance of Photosynthesis:\n",
      "Photosynthesis is essential for life on Earth as it provides the oxygen we breathe and forms the base of the food chain by producing organic compounds that serve as energy sources for other organisms.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Batch processing multiple prompts\n",
    "prompts = [\n",
    "    \"Summarize the benefits of renewable energy.\",\n",
    "    \"Explain the water cycle in 3 steps.\",\n",
    "    \"What are the primary colors?\",\n",
    "    \"Define artificial intelligence.\",\n",
    "    \"How does photosynthesis work?\"\n",
    "]\n",
    "\n",
    "# Send all prompts to the model in a single batch request\n",
    "responses = llm.batch(prompts)\n",
    "\n",
    "# Display each prompt and its corresponding model response\n",
    "for i, response in enumerate(responses):\n",
    "    print(f\"Prompt {i+1}: {prompts[i]}\")\n",
    "    print(f\"Response: {response.content}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20mtYRhQx3my"
   },
   "source": [
    "- `llm.batch(prompts)`: Sends all the input prompts to the model in one call. It returns a list of response objects, one per input. This is significantly more efficient than looping over `llm.invoke()` individually.\n",
    "\n",
    "Batch processing is more efficient than individual calls for:\n",
    "  - Reduces network latency and API overhead.\n",
    "  - Makes better use of model rate limits and throughput.\n",
    "  - Faster overall processing time.\n",
    "\n",
    "#### Asynchronous batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "8pg-W5Fdx3my"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is machine learning?\n",
      "A: Machine learning is a subset of artificial intelligence (AI) that focuses on the development of algo...\n",
      "------------------------------\n",
      "Q: Explain blockchain technology.\n",
      "A: Blockchain technology is a decentralized digital ledger system that records transactions across many...\n",
      "------------------------------\n",
      "Q: How do vaccines work?\n",
      "A: Vaccines work by stimulating the immune system to recognize and fight specific pathogens, such as vi...\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Async batch processing for better performance\n",
    "async def async_batch_example():\n",
    "    prompts = [\n",
    "        \"What is machine learning?\",\n",
    "        \"Explain blockchain technology.\",\n",
    "        \"How do vaccines work?\"\n",
    "    ]\n",
    "\n",
    "    # Send the prompts concurrently using the async abatch method\n",
    "    responses = await llm.abatch(prompts)\n",
    "\n",
    "    # Display each result\n",
    "    for prompt, response in zip(prompts, responses):\n",
    "        print(f\"Q: {prompt}\")\n",
    "        print(f\"A: {response.content[:100]}...\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "await async_batch_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQCIf59Hx3my"
   },
   "source": [
    "- `await llm.abatch(prompts)`: Performs batch processing asynchronously — meaning it doesn't block the execution thread.\n",
    "- Uses `async` and `await` to allow concurrent task execution (e.g., handling multiple users in a web app).\n",
    "\n",
    "Async batch processing allows for:\n",
    "  - Improves application responsiveness — other tasks can run while waiting for responses.\n",
    "  - Scales better under load — handles many requests without blocking.\n",
    "  - Maximizes resource usage (CPU, I/O, etc.) with non-blocking behavior."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
